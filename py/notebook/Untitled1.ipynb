{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from goose3 import Goose\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import MySQLdb as mdb\n",
    "import collections\n",
    "import requests\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baca_word = ['Informasi Menarik Terbaru','Membaca:','Baca juga','Baca :','BACA JUGA:','Artikel ini telah tayang di',\n",
    "            'Baca:','BACA :','Baca Juga:','Baca artikel sumber','Penulis :']\n",
    "\n",
    "user_agent = ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6)'\n",
    "              ' AppleWebKit/537.36 (KHTML, like Gecko)'\n",
    "              ' Chrome/58.0.3029.96 Safari/537.36')\n",
    "\n",
    "known_pattern = json.loads(open(\"pattern.json\", \"r\").read())\n",
    "\n",
    "g = Goose({\n",
    "            'enable_image_fetching': False,\n",
    "            'use_meta_language': False,\n",
    "            'target_language': \"id\",\n",
    "            'browser_user_agent': user_agent,\n",
    "            'known_context_patterns': known_pattern,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_news = [\n",
    "    {\n",
    "        \"kanal\": \"bisnis\",\n",
    "        \"link\": \"CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtbGtHZ0pKUkNnQVAB\"\n",
    "    },\n",
    "    {\n",
    "        \"kanal\": \"teknologi\",\n",
    "        \"link\": \"CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtbGtHZ0pKUkNnQVAB\"\n",
    "    },\n",
    "    {\n",
    "        \"kanal\": \"hiburan\",\n",
    "        \"link\": \"CAAqJggKIiBDQkFTRWdvSUwyMHZNREpxYW5RU0FtbGtHZ0pKUkNnQVAB\"\n",
    "    },\n",
    "    {\n",
    "        \"kanal\": \"olahraga\",\n",
    "        \"link\": \"CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp1ZEdvU0FtbGtHZ0pKUkNnQVAB\"\n",
    "    },\n",
    "    {\n",
    "        \"kanal\": \"sains\",\n",
    "        \"link\": \"CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp0Y1RjU0FtbGtHZ0pKUkNnQVAB\"\n",
    "    },\n",
    "    {\n",
    "        \"kanal\": \"kesehatan\",\n",
    "        \"link\": \"CAAqIQgKIhtDQkFTRGdvSUwyMHZNR3QwTlRFU0FtbGtLQUFQAQ\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_kanal_links():\n",
    "    all_kanal_links = []\n",
    "    for kanal in google_news:\n",
    "        url = \"https://news.google.com/topics/{link}?hl=id&gl=ID&ceid=ID%3Aid\".format(link=kanal['link'])\n",
    "        all_kanal_links.append([kanal['kanal'],url])\n",
    "        \n",
    "    return all_kanal_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_title(title):\n",
    "    sparator = [' |',' -',' –']\n",
    "    for s in sparator:\n",
    "        title_ = title.split(s)\n",
    "        \n",
    "        if title_[0] == title:\n",
    "            pass\n",
    "        else:\n",
    "            if len(title[0]) < 20:\n",
    "                title_fix = title_[1]\n",
    "            else:\n",
    "                title_fix = title_[0]\n",
    "               \n",
    "    return title_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_content(text):    \n",
    "    junk_word = []\n",
    "    for word in baca_word:\n",
    "        for i in text.split('.'):\n",
    "            if i.find(word) >= 0 :\n",
    "                junk_word.append(i)\n",
    "\n",
    "    for j in junk_word:\n",
    "        text = text.replace(j, ' ')\n",
    "        \n",
    "    text = text.replace('..','.').replace('. . ','. ')\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_content(link):\n",
    "    redirect = requests.get(link, timeout=5, allow_redirects=True)\n",
    "    \n",
    "    if 'www.youtube.com' in redirect.url:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            extract = g.extract(redirect.url)\n",
    "\n",
    "            title = extract.title\n",
    "            title = cleaning_title(title)\n",
    "            final_title = re.sub(r'[^\\x00-\\x7F]+', '', title)\n",
    "\n",
    "            content = cleaning_content(extract.cleaned_text)\n",
    "            content = content.replace('‘','').replace('\\n\\n','\\n').replace('\\n\\n','\\n').replace('\\n',' ').replace('  ',' ').replace('- ','')\n",
    "            content = content.strip()\n",
    "            final_content = re.sub(r'[^\\x00-\\x7F]+', '', content)\n",
    "\n",
    "            if len(content) > 100:\n",
    "                final_content = final_content\n",
    "            else:\n",
    "                final_content = \"Not Valid\"\n",
    "            \n",
    "            if final_title == \"\" or final_content == \"Not Valid\" or final_content == \"\":\n",
    "                result = \"Invalid\"\n",
    "            else:\n",
    "                result = {\n",
    "                    'url': redirect.url,\n",
    "                    'title': final_title,\n",
    "                    'spoiler': '{content}...'.format(content=final_content[:297]),\n",
    "                    'content': final_content\n",
    "                }\n",
    "        except:\n",
    "            result = \"Invalid\"\n",
    "\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_one_kanal(kanal):\n",
    "    all_kanal_links = get_all_kanal_links()\n",
    "    link_kanal = declare_link_kanal(kanal)\n",
    "    page = requests.get(link_kanal)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    href = soup.find_all(\"a\", {\"class\" : \"VDXfz\"})\n",
    "\n",
    "    links_one_kanal = []\n",
    "    for h in href:\n",
    "        h = h['href'].replace('./articles','https://news.google.com/articles')\n",
    "        links_one_kanal.append(h)\n",
    "    \n",
    "    \n",
    "\n",
    "    return links_one_kanal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_to_db(kanal):\n",
    "    for k in kanal:\n",
    "        print(\"Scraping kanal '%s' ..\" %k)\n",
    "        links_one_kanal = get_link_one_kanal(k)\n",
    "        \n",
    "        con = mdb.connect(host, user, password, db, charset='utf8')\n",
    "#         counter = 1\n",
    "        total = len(links_one_kanal)\n",
    "    \n",
    "        counter = collections.Counter()\n",
    "        \n",
    "        for i in tqdm(range(len(links_one_kanal[:3]))):\n",
    "            result = get_content(links_one_kanal[i])\n",
    "\n",
    "            if result == \"Invalid\":\n",
    "                counter['Failed'] += 1\n",
    "#                 print(\"%d/%d | ERROR | %s \" %(counter,total,link))\n",
    "#                 counter += 1\n",
    "                pass\n",
    "            else:\n",
    "                url = result['url']\n",
    "                title = result['title']\n",
    "                spoiler = result['spoiler']\n",
    "                content = result['content']\n",
    "\n",
    "                sql = '''INSERT INTO {table} VALUES (0,\"{url}\",\"{title}\",\"{spoiler}\",\"{content}\",NOW())'''.format(\n",
    "                    table=k.lower(),\n",
    "                    url=url,\n",
    "                    title=title,\n",
    "                    spoiler=spoiler,\n",
    "                    content=content\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    cur = con.cursor()\n",
    "                    cur.execute(sql)\n",
    "                    con.commit()\n",
    "                    \n",
    "                    counter['Succes'] += 1\n",
    "#                     print(\"%d/%d | SUCCES | %s \" %(counter,total,title))\n",
    "#                     counter += 1\n",
    "                except:\n",
    "                    counter['Failed'] += 1\n",
    "#                     print(\"%d/%d | FAILED | %s \" %(counter,total,title))\n",
    "#                     counter += 1\n",
    "                    pass\n",
    "        print(counter)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping kanal 'BISNIS' ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Failed': 3})\n",
      "Scraping kanal 'TEKNOLOGI' ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Failed': 2, 'Succes': 1})\n",
      "Scraping kanal 'HIBURAN' ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Failed': 3})\n",
      "Scraping kanal 'OLAHRAGA' ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Failed': 2, 'Succes': 1})\n",
      "Scraping kanal 'SAINS' ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Failed': 3})\n",
      "Scraping kanal 'KESEHATAN' ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Failed': 3})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_kanal = [\"BISNIS\",\"TEKNOLOGI\",\"HIBURAN\",\"OLAHRAGA\",\"SAINS\",\"KESEHATAN\"]\n",
    "\n",
    "save_to_db(all_kanal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global-ENV",
   "language": "python",
   "name": "global-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
